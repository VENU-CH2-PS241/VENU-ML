{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "import string\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c126dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_factory = StopWordRemoverFactory()\n",
    "more_stopword = ['dengan', 'ia','bahwa','oleh']\n",
    "data = stop_factory.get_stop_words()+more_stopword\n",
    "stopword = stop_factory.create_stop_word_remover()\n",
    "\n",
    "Fact = StemmerFactory()\n",
    "stemmer = Fact.create_stemmer()\n",
    "# lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8470f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(cwd, 'dataset')\n",
    "\n",
    "files = []\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(os.path.join(data_path, file))\n",
    "        \n",
    "print(files, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79135821",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data1 = pd.read_csv(files[1], sep = ';', encoding_errors = 'ignore')\n",
    "raw_data2 = pd.read_csv(files[2], sep = ';', encoding_errors = 'ignore')\n",
    "raw_data3 = pd.read_csv(files[4], sep = ';', encoding_errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e500ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e44af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = raw_data3.drop(columns = raw_data3.columns[3:])\n",
    "data3.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7655c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = raw_data1[['berita', 'kategori']]\n",
    "data1.rename(columns = {'kategori' : 'label'}, inplace = True)\n",
    "\n",
    "data2 = raw_data2.rename(columns = {'tagging' : 'label'})\n",
    "\n",
    "data3 = raw_data3[['Body', 'Label']]\n",
    "data3.rename(columns = {'Label' : 'label', 'Body' : 'berita'}, inplace = True)\n",
    "\n",
    "data1.columns, data2.columns, data3.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data1, data2, data3], ignore_index = True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92258a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaccf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label = df.label.replace(['valid', 'hoax', 'Valid', 'Hoax'], [0, 1, 0, 1])\n",
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036c4a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.label.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa593781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79840aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.berita[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_path = os.path.join(data_path, 'archive', 'Summarized')\n",
    "tempo_sum = pd.read_excel(os.path.join(archive_path, 'dataset_tempo_summarized.xlsx'), index_col = 'index')\n",
    "cnn_sum = pd.read_excel(os.path.join(archive_path, 'dataset_cnn_summarized.xlsx'), index_col = 'index')\n",
    "kompas_sum = pd.read_excel(os.path.join(archive_path, 'dataset_kompas_summarized.xlsx'), index_col = 'index')\n",
    "tbhoax_sum = pd.read_excel(os.path.join(archive_path, 'dataset_turnbackhoax_summarized.xlsx'), index_col = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43573c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_sum.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef43c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sum.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "kompas_sum.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbhoax_sum.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(text):\n",
    "    text = re.sub(r'http\\S+', '', text.lower())\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "#     text = tokenizer(text)\n",
    "    text = stemmer.stem(text)\n",
    "    text = stopword.remove(text)\n",
    "    return text.split()\n",
    "\n",
    "pipeline(cnn_sum.cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1021b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_processed = X.apply(lambda x : pipeline(x))\n",
    "\n",
    "df_processed = pd.DataFrame({\n",
    "    'berita' : X_processed,\n",
    "    'label' : y\n",
    "})\n",
    "\n",
    "# df_processed.to_csv(os.path.join(data_path, 'df_processed.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
