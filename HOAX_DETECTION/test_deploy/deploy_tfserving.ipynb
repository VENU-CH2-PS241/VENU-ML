{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\LENOVO\\GitHub\\bangkit_capstone\\VENU-ML\\HOAX_DETECTION\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "df = pd.read_csv('datasets/cnn_content_2023-11-11.csv')\n",
        "df = df[['berita']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "272"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = df.sample()\n",
        "\n",
        "# df_test.cleaned.values\n",
        "len(df_test['berita'].values[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Undang-undang Nomor 7 Tahun 2017 tentang Pemilu melarang tim kampanye pasangan capres-cawapres mengikutsertakan hakim Mahkamah Konstitusi (MK) hingga komisaris serta direksi Badan Usaha Milik Negara (BUMN) atau BUMD dalam kegiatan kampanye Pilpres 2024. Hal ini diatur dalam UU Pemilu Pasal 280 ayat (2) huruf a dan d yang berbunyi sebagai berikut. \"Pelaksana dan/atau tim kampanye dalam kegiatan Kampanye Pemilu dilarang mengikutsertakan: a. Ketua, wakil ketua, ketua muda, hakim agung pada Mahkamah Agung, dan hakim pada semua badan peradilan di bawah Mahkamah Agung, dan hakim konstitusi pada Mahkamah Konstitusi,\"   \"d. direksi, komisaris, dewan pengawas dan karyawan badan usaha milik negara/badan usaha milik daerah.\"  Hakim MK dan komisaris BUMN/BUMD juga dilarang menjadi pelaksana maupun tim sukses kampanye paslon tertentu. Aturan ini pun berlaku bagi ketua, wakil ketua, dan anggota BPK; gubernur, deputi gubernur senior, dan deputi gubernur BI. Kemudian pejabat negara yang menjabat sebagai pimpinan di lembaga nonstruktural; ASN; anggota TNI/Polri; kepala desa; perangkat desa; hingga anggota badan permusyawaratan desa. Hal ini diatur dalam Pasal 280 ayat (3) yang berbunyi sebagai berikut.\"(3) Setiap orang sebagaimana dimaksud pada ayat (2) dilarang ikut serta sebagai pelaksana dan tim Kampanye Pemilu.\" Bila tim kampanye capres tertentu melanggar lantaran masih melibatkan pihak-pihak tersebut, maka mereka dapat dikenakan sanksi berupa pidana penjara selama setahun dan denda Rp12 juta. \"Setiap pelaksana dan/atau tim kampanye pemilu yang melanggar larangan sebagaimana dimaksud dalam Pasal 280 ayat (2) dipidana dengan pidana kurungan paling lama 1 (satu) tahun dan denda paling banyak Rp12.000.000,00 (dua belas juta rupiah),\" bunyi Pasal 493. Pilpres 2024 diperkirakan akan diikuti oleh tiga pasangan capres-cawapres. Mereka di antaranya pasangan Ganjar Pranowo-Mahfud MD, Prabowo Subianto-Gibran Rakabuming Raka dan Anies Baswedan-Muhaimin Iskandar.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['berita'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 70), dtype=int32, numpy=\n",
              "array([[    2,  9363, 29947,  9363,  1288,   680,   262,  3951,   416,\n",
              "         4482,  8051,   511,  6343,  2038, 15994, 29947, 25951, 11245,\n",
              "        22672,  4887, 10354,  7343, 29942,  8221, 29943,   733, 13741,\n",
              "          501, 12403,  1269,  1062,  2318,   664, 29942,  4098, 29943,\n",
              "          158, 23514,   112,   845,  6343, 15140, 23917, 29860, 29948,\n",
              "          269,    92,  4573,   112,  3719,  4482,  2051, 24798,  1862,\n",
              "        29942,   109, 29943,  3307,   253,    41,     6,    34, 10388,\n",
              "          242,   713, 29948, 29936,  7416,    41,     3]])>, 'attention_mask': <tf.Tensor: shape=(1, 70), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]])>}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-lite-base-p1')\n",
        "\n",
        "max_len = 70\n",
        "\n",
        "tokenized = tokenizer(\n",
        "    text=df_test['berita'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        ")\n",
        "\n",
        "tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1 = np.squeeze(tokenized['attention_mask']._numpy())\n",
        "X2 = np.squeeze(tokenized['input_ids']._numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'predictions': [[0.0207458735]]}\n"
          ]
        }
      ],
      "source": [
        "data1 = json.dumps({\"signature_name\": \"serving_default\",\n",
        "                   \"instances\": [{'attention_mask':X1.tolist(),'input_ids':X2.tolist()}]})\n",
        "# both x and y are numpy 2d array \n",
        "\n",
        "json_response = requests.post('http://localhost:8501/v1/models/NLP:predict',\n",
        "                               data=data1)\n",
        "\n",
        "pred = json.loads(json_response.text)\n",
        "\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['attention_mask'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_attention_mask:0\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_input_ids:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'ReadVariableOp', 'VarHandleOp', 'Const', 'StridedSlice', 'Prod', 'Shape', 'Identity', 'DisableCopyOnRead', 'Rsqrt', 'Mul', 'Cast', 'Tanh', 'NoOp', 'Transpose', 'RealDiv', 'BiasAdd', 'SaveV2', 'Reshape', 'Softmax', 'AddV2', 'Sub', 'Fill', 'Select', 'Pack', 'Relu', 'StringJoin', 'Range', 'Less', 'StatefulPartitionedCall', 'StopGradient', 'StaticRegexFullMatch', 'ShardedFilename', 'Mean', 'Sigmoid', 'ExpandDims', 'BatchMatMulV2', 'AssignVariableOp', 'Placeholder', 'MergeV2Checkpoints', 'Max', 'SquaredDifference', 'RestoreV2', 'GatherV2', 'All', 'Erf', 'ConcatV2', 'MatMul', 'Assert', 'ResourceGather'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-10 10:04:53.302482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 92, in NewCheckpointReader\n",
            "    return CheckpointReader(compat.as_bytes(filepattern))\n",
            "RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/2\\variables\\variables\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 988, in load_partial\n",
            "    loader = Loader(object_graph_proto, saved_model_proto, export_dir,\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 205, in __init__\n",
            "    self._restore_checkpoint()\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 540, in _restore_checkpoint\n",
            "    load_status = saver.restore(variables_path, self._checkpoint_options)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py\", line 1415, in restore\n",
            "    reader = py_checkpoint_reader.NewCheckpointReader(save_path)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 96, in NewCheckpointReader\n",
            "    error_translator(e)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 31, in error_translator\n",
            "    raise errors_impl.NotFoundError(None, None, error_message)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/2\\variables\\variables\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\LENOVO\\GitHub\\bangkit_capstone\\VENU-ML\\HOAX_DETECTION\\venv\\Scripts\\saved_model_cli.exe\\__main__.py\", line 7, in <module>\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 1309, in main\n",
            "    app.run(smcli_main)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\absl\\app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\absl\\app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 1307, in smcli_main\n",
            "    args.func()\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 968, in show\n",
            "    _show_all(_SMCLI_DIR.value)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 531, in _show_all\n",
            "    _show_defined_functions(saved_model_dir, saved_model.meta_graphs)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 405, in _show_defined_functions\n",
            "    trackable_object = load.load(saved_model_dir)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 858, in load\n",
            "    result = load_partial(export_dir, None, tags, options)[\"root\"]\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 991, in load_partial\n",
            "    raise FileNotFoundError(\n",
            "FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/2\\variables\\variables\n",
            " You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.\n",
            "2023-12-10 10:05:16.435002: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['attention_mask'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_attention_mask:0\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_input_ids:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'Shape', 'StaticRegexFullMatch', 'VarHandleOp', 'Select', 'Sigmoid', 'Assert', 'GatherV2', 'Const', 'Erf', 'Rsqrt', 'ExpandDims', 'Placeholder', 'Prod', 'AssignVariableOp', 'ShardedFilename', 'Max', 'Less', 'StopGradient', 'ConcatV2', 'Pack', 'ResourceGather', 'Fill', 'Transpose', 'NoOp', 'RestoreV2', 'All', 'DisableCopyOnRead', 'Mean', 'MergeV2Checkpoints', 'Reshape', 'StridedSlice', 'Identity', 'StatefulPartitionedCall', 'Range', 'Sub', 'BatchMatMulV2', 'MatMul', 'ReadVariableOp', 'Cast', 'SaveV2', 'Tanh', 'Mul', 'RealDiv', 'SquaredDifference', 'AddV2', 'StringJoin', 'BiasAdd', 'Relu', 'Softmax'}\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/1 --all"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
