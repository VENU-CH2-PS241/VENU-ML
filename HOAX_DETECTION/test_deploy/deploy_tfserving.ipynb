{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\LENOVO\\GitHub\\bangkit_capstone\\VENU-ML\\HOAX_DETECTION\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "df = pd.read_excel('datasets/dataset_turnbackhoax_summarized.xlsx')\n",
        "df = df[['cleaned', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = df.sample()\n",
        "\n",
        "# df_test.cleaned.values\n",
        "len(df_test['cleaned'].values[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 70), dtype=int32, numpy=\n",
              "array([[    2,  2641,  9642, 29945,  9286, 12160, 29859, 29947,  4287,\n",
              "         1909, 29947, 11808,  8165,   154,  2318,  1225,  4310, 23113,\n",
              "        29081, 20944,  4235, 29848,     3,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(1, 70), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0]])>}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-lite-base-p1')\n",
        "\n",
        "max_len = 70\n",
        "\n",
        "tokenized = tokenizer(\n",
        "    text=df_test['cleaned'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        ")\n",
        "\n",
        "tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1 = np.squeeze(tokenized['attention_mask']._numpy())\n",
        "X2 = np.squeeze(tokenized['input_ids']._numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'predictions': [[0.99728781]]}\n"
          ]
        }
      ],
      "source": [
        "data1 = json.dumps({\"signature_name\": \"serving_default\",\n",
        "                   \"instances\": [{'attention_mask':X1.tolist(),'input_ids':X2.tolist()}]})\n",
        "# both x and y are numpy 2d array \n",
        "\n",
        "json_response = requests.post('http://localhost:8501/v1/models/NLP:predict',\n",
        "                               data=data1)\n",
        "\n",
        "pred = json.loads(json_response.text)\n",
        "\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['attention_mask'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_attention_mask:0\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_input_ids:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'ReadVariableOp', 'VarHandleOp', 'Const', 'StridedSlice', 'Prod', 'Shape', 'Identity', 'DisableCopyOnRead', 'Rsqrt', 'Mul', 'Cast', 'Tanh', 'NoOp', 'Transpose', 'RealDiv', 'BiasAdd', 'SaveV2', 'Reshape', 'Softmax', 'AddV2', 'Sub', 'Fill', 'Select', 'Pack', 'Relu', 'StringJoin', 'Range', 'Less', 'StatefulPartitionedCall', 'StopGradient', 'StaticRegexFullMatch', 'ShardedFilename', 'Mean', 'Sigmoid', 'ExpandDims', 'BatchMatMulV2', 'AssignVariableOp', 'Placeholder', 'MergeV2Checkpoints', 'Max', 'SquaredDifference', 'RestoreV2', 'GatherV2', 'All', 'Erf', 'ConcatV2', 'MatMul', 'Assert', 'ResourceGather'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-10 10:04:53.302482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 92, in NewCheckpointReader\n",
            "    return CheckpointReader(compat.as_bytes(filepattern))\n",
            "RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/2\\variables\\variables\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 988, in load_partial\n",
            "    loader = Loader(object_graph_proto, saved_model_proto, export_dir,\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 205, in __init__\n",
            "    self._restore_checkpoint()\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 540, in _restore_checkpoint\n",
            "    load_status = saver.restore(variables_path, self._checkpoint_options)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\checkpoint\\checkpoint.py\", line 1415, in restore\n",
            "    reader = py_checkpoint_reader.NewCheckpointReader(save_path)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 96, in NewCheckpointReader\n",
            "    error_translator(e)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 31, in error_translator\n",
            "    raise errors_impl.NotFoundError(None, None, error_message)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/2\\variables\\variables\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\LENOVO\\GitHub\\bangkit_capstone\\VENU-ML\\HOAX_DETECTION\\venv\\Scripts\\saved_model_cli.exe\\__main__.py\", line 7, in <module>\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 1309, in main\n",
            "    app.run(smcli_main)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\absl\\app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\absl\\app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 1307, in smcli_main\n",
            "    args.func()\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 968, in show\n",
            "    _show_all(_SMCLI_DIR.value)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 531, in _show_all\n",
            "    _show_defined_functions(saved_model_dir, saved_model.meta_graphs)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\tools\\saved_model_cli.py\", line 405, in _show_defined_functions\n",
            "    trackable_object = load.load(saved_model_dir)\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 858, in load\n",
            "    result = load_partial(export_dir, None, tags, options)[\"root\"]\n",
            "  File \"c:\\users\\lenovo\\github\\bangkit_capstone\\venu-ml\\hoax_detection\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 991, in load_partial\n",
            "    raise FileNotFoundError(\n",
            "FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/2\\variables\\variables\n",
            " You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.\n",
            "2023-12-10 10:05:16.435002: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['attention_mask'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_attention_mask:0\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 70)\n",
            "        name: serving_default_input_ids:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "The MetaGraph with tag set ['serve'] contains the following ops: {'Shape', 'StaticRegexFullMatch', 'VarHandleOp', 'Select', 'Sigmoid', 'Assert', 'GatherV2', 'Const', 'Erf', 'Rsqrt', 'ExpandDims', 'Placeholder', 'Prod', 'AssignVariableOp', 'ShardedFilename', 'Max', 'Less', 'StopGradient', 'ConcatV2', 'Pack', 'ResourceGather', 'Fill', 'Transpose', 'NoOp', 'RestoreV2', 'All', 'DisableCopyOnRead', 'Mean', 'MergeV2Checkpoints', 'Reshape', 'StridedSlice', 'Identity', 'StatefulPartitionedCall', 'Range', 'Sub', 'BatchMatMulV2', 'MatMul', 'ReadVariableOp', 'Cast', 'SaveV2', 'Tanh', 'Mul', 'RealDiv', 'SquaredDifference', 'AddV2', 'StringJoin', 'BiasAdd', 'Relu', 'Softmax'}\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask')]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir C:/Users/LENOVO/GitHub/bangkit_capstone/VENU-ML/HOAX_DETECTION/test_deploy/model/1 --all"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
